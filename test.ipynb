{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skfuzzy as fuzz\n",
    "def fuzzy_C(image,n_classes):\n",
    "    # Flatten the image array and normalize\n",
    "    data = image.flatten()\n",
    "    data_norm = data / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Reshape data for clustering\n",
    "    data_reshaped = data_norm.reshape((1, -1))\n",
    "\n",
    "    # Specify the number of clusters\n",
    "    clusters = n_classes\n",
    "\n",
    "    # Apply Fuzzy C-means\n",
    "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "        data_reshaped, clusters, 2, error=0.005, maxiter=1000, init=None)\n",
    "\n",
    "    # Find the cluster membership for each pixel\n",
    "    cluster_membership = np.argmax(u, axis=0)\n",
    "\n",
    "    # Map back to image shape\n",
    "    segmented_image = cluster_membership.reshape(image.shape)\n",
    "\n",
    "    # Convert the segmented image into uint8 (for displaying)\n",
    "    segmented_image = np.uint8(255 * segmented_image / clusters)\n",
    "    return segmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.perspective import four_point_transform \n",
    "\n",
    "# cap = cv2.VideoCapture(1)\n",
    "# # +cv2.CAP_DSHOW\n",
    "# if not cap.isOpened():\n",
    "#     print(\"Cannot open camera\")\n",
    "#     exit()\n",
    "\n",
    "WIDTH, HEIGHT = 600, 300\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)\n",
    "\n",
    "\n",
    "def scan_detection_1(image_,bl_sz,const):\n",
    "    global document_contour\n",
    "    image=image_\n",
    "    im_cop=image_\n",
    "    # khởi tạo contour đầu tiên, bằng kích thước của frame\n",
    "    document_contour= np.array([[0,0],[WIDTH,0],[WIDTH,HEIGHT],[0,HEIGHT]])\n",
    "\n",
    "    # xử lý ảnh cơ bản, chuyển màu gray, blur ảnh để chống nhiễu và giảm độ chi tiết \n",
    "    gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur= cv2.GaussianBlur(gray, (15,15),0)\n",
    "    # blur= cv2.GaussianBlur(blur, (5,5),0)\n",
    "    # blur= cv2.GaussianBlur(blur, (5,5),0)\n",
    "    # blur= cv2.GaussianBlur(blur, (5,5),0)\n",
    "    frame_gray= cv2.adaptiveThreshold(\n",
    "    blur,                # source image\n",
    "    255,                       # max value to use with the THRESH_BINARY\n",
    "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C, # adaptive method, Gaussian weighting\n",
    "    cv2.THRESH_BINARY,         # threshold type\n",
    "    bl_sz,                        # block size: size of a pixel neighborhood used to calculate threshold value\n",
    "    const                       # constant subtracted from the mean or weighted sum\n",
    "    )\n",
    "    # frame_gray = cv2.Canny(blur, 100, 300)\n",
    "\n",
    "    dst = cv2.cornerHarris(frame_gray, blockSize=2, ksize=3, k=0.04)\n",
    "    # Result is dilated for marking the corners\n",
    "    dst = cv2.dilate(dst, None)\n",
    "    # Threshold for an optimal value, marking the corners in red\n",
    "    im_cop[dst > 0.1 * dst.max()] = [0, 0, 255]\n",
    "    contours,_ = cv2.findContours(frame_gray, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours=sorted(contours, key=cv2.contourArea,reverse=True)\n",
    "    max_area= 500\n",
    "    for contour in contours:\n",
    "        area=cv2.contourArea(contour)\n",
    "        print(area)\n",
    "        if area > 100:\n",
    "            peri = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.15*peri, True)\n",
    "            print(len(approx))\n",
    "            if  area > max_area:#and len(approx)==4\n",
    "                print(f\"accepted area {area}\")\n",
    "                document_contour=approx\n",
    "                max_area=area\n",
    "    cv2.drawContours(image,[document_contour],-1,(0,255,0),3)\n",
    "    return image,blur,frame_gray,contours,im_cop,bl_sz,const\n",
    "\n",
    "imagea=cv2.imread(\"/Users/mac/Dev/Computer_Vision/Image 2.jpeg\")\n",
    "if imagea is None:\n",
    "    print(\"Failed to load image\")\n",
    "    exit()\n",
    "for bll in range(3,25,2):\n",
    "    for c in range(3,25,2):\n",
    "        im,bl,gr,con,corner,bl,cons=scan_detection_1(imagea,bll,c)\n",
    "        cv2.imwrite(f\"/Users/mac/Dev/Computer_Vision/outputs/corner/image_{bl}_{cons}.jpg\",im)\n",
    "# cv2.imshow(\"m\", im)\n",
    "# cv2.imshow(\"blurred\",bl)\n",
    "# cv2.imshow(\"gray\",gr)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "#         break\n",
    "#     # frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "    \n",
    "#     frame_copy = frame.copy()\n",
    "#     _1,_2,_3=scan_detection_1(frame_copy)\n",
    "#     # c=fuzzy_C(frame_copy,5)\n",
    "#     cv2.imshow(\"custom_1\",_1)\n",
    "#     if cv2.waitKey(1) & 0xFF == 27:\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.perspective import four_point_transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 15:43:09.964 Python[49698:11941627] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "2024-04-24 15:43:12.012 Python[49698:11941627] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.perspective import four_point_transform\n",
    "import pytesseract\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "WIDTH, HEIGHT = 800, 600\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)\n",
    "\n",
    "\n",
    "def scan_detection(image):\n",
    "    global document_contour\n",
    "\n",
    "    document_contour = np.array([[0, 0], [WIDTH, 0], [WIDTH, HEIGHT], [0, HEIGHT]])\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    dst = cv2.cornerHarris(gray, blockSize=3, ksize=5, k=0.07)\n",
    "    # Result is dilated for marking the corners\n",
    "    dst = cv2.dilate(dst, None)\n",
    "    # Threshold for an optimal value, marking the corners in red\n",
    "    frame[dst > 0.1 * dst.max()] = [0, 0, 255]\n",
    "\n",
    "    _, threshold = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    max_area = 500000\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 400000:\n",
    "            peri = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.015 * peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                document_contour = approx\n",
    "                max_area = area\n",
    "\n",
    "    cv2.drawContours(frame, [document_contour], -1, (0, 255, 0), 3)\n",
    "    return threshold \n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    thrh=scan_detection(frame_copy)\n",
    "\n",
    "    cv2.imshow(\"input\", frame)\n",
    "    cv2.imshow(\"ouput\", thrh)\n",
    "\n",
    "    # warped = four_point_transform(frame_copy, document_contour.reshape(4, 2))\n",
    "    # cv2.imshow(\"Warped\", warped)\n",
    "\n",
    "    # print(ocr_text)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
